{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, default_data_collator, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "from arguments import DataTrainingArguments, ModelArguments, TrainingArguments\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base', legacy=True)\n",
    "\n",
    "# Initialize the data arguments\n",
    "data_args = DataTrainingArguments(\n",
    "    datasets='floorplan',\n",
    "    data_dir=None,\n",
    "    train_split='train',\n",
    "    max_seq_length=512,\n",
    "    max_output_seq_length=512,\n",
    "    max_seq_length_eval=512,\n",
    "    max_output_seq_length_eval=512,\n",
    "    exp='full',\n",
    "    boundary_in_where='Encoder'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "model_args = ModelArguments(model_name_or_path='t5-base', config_name=None, tokenizer_name=None, cache_dir=None)\n",
    "\n",
    "training_args = TrainingArguments()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.do_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    padding=\"max_length\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example input sententece: Balcony 1 is about 8 foot X 2 foot . This is located right off of the kitchen . Balcony 2 is about 10 foot X 3 foot . This is facing north of the house . The bathroom is about 8 foot X 6 foot . It is located between the living room and the kitchen . Common room 1 is about 10 foot X 12 foot . The common rooms are located diagonal from each other . Common room 2 is about 10 foot X 10 foot . The common rooms are located diagonal from each other . The kitchen is a 10 foot X 10 foot room . It looks like it is opened up to the living room . The living room is located on the east side of the house . It is shaped like a T and it's the biggest room . It is approximately 14 feet X 32 feet . Each room that you come out of you will enter the living room . The master is about 10 feet X 15 feet . It is located far west of the house . It is a rectangle shape .+ 43 51 213 205 - 196 202 218 180 - 175 79 202 52 - 170 122 224 68 - 132 83 165 50 - 42 115 106 50 - 42 203 57 188\n",
      "Example output sententece: bathroom 137 125 170 144 kitchen 176 150 208 179 balcony 2 48 150 67 200 master room 73 56 131 97 common room 1 137 73 170 119 living room 73 103 195 200 common room 2 73 103 113 144 balcony 1 176 133 208 144 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Max sequence length is 512 but the longest input sequence is 849 long\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfloorplan\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mmax_input_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_seq_length\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_output_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_output_seq_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_subset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_subset\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/datasets.py:57\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(dataset_name, data_args, tokenizer, split, max_input_length, max_output_length, train_subset, seed, shuffle, is_eval)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_dataset\u001B[39m(\n\u001B[1;32m     43\u001B[0m         dataset_name: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m     44\u001B[0m         data_args: DataTrainingArguments,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     52\u001B[0m         is_eval: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     53\u001B[0m ):\n\u001B[1;32m     54\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;124;03m    Load a registered dataset.\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDATASETS\u001B[49m\u001B[43m[\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_input_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_input_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_output_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_output_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[43m        \u001B[49m\u001B[43moverwrite_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moverwrite_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_subset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_subset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/base_dataset.py:92\u001B[0m, in \u001B[0;36mBaseDataset.__init__\u001B[0;34m(self, tokenizer, max_input_length, max_output_length, overwrite_cache, mode, local_rank, train_subset, seed, shuffle, data_args, is_eval)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m example \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexamples:\n\u001B[1;32m     90\u001B[0m     example\u001B[38;5;241m.\u001B[39mdataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\n\u001B[0;32m---> 92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_features\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_input_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_input_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_output_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_output_length\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmultitask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmultitask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m local_rank \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m# save data\u001B[39;00m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_data(cached_data_file)\n",
      "File \u001B[0;32m~/Developer/projects/t2f/base_dataset.py:260\u001B[0m, in \u001B[0;36mBaseDataset.compute_features\u001B[0;34m(self, max_input_length, max_output_length, multitask)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_warn_max_sequence_length(max_output_length, output_sentences, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    252\u001B[0m boundary_tok \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtokenizer\u001B[38;5;241m.\u001B[39mbatch_encode_plus(\n\u001B[1;32m    253\u001B[0m     boundary_sentences,\n\u001B[1;32m    254\u001B[0m     max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    257\u001B[0m     truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    258\u001B[0m )\n\u001B[0;32m--> 260\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[43minput_tok\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m output_tok[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    261\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m input_tok\u001B[38;5;241m.\u001B[39minput_ids\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m==\u001B[39m boundary_tok\u001B[38;5;241m.\u001B[39minput_ids\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    263\u001B[0m features \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('floorplan', data_args, split='train',\n",
    "                         max_input_length=data_args.max_seq_length, max_output_length=data_args.max_output_seq_length,\n",
    "                         tokenizer=tokenizer, seed=1, train_subset=data_args.train_subset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, mlm_probability=0.15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=floorplan_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 28 at dim 1 (got 24)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/transformers/trainer.py:1780\u001B[0m, in \u001B[0;36mTrainer.train\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   1778\u001B[0m         hf_hub_utils\u001B[38;5;241m.\u001B[39menable_progress_bars()\n\u001B[1;32m   1779\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1780\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1781\u001B[0m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1782\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1783\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1784\u001B[0m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1785\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/transformers/trainer.py:2085\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2082\u001B[0m     rng_to_sync \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   2084\u001B[0m step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 2085\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, inputs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(epoch_iterator):\n\u001B[1;32m   2086\u001B[0m     total_batched_samples \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2088\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39minclude_num_input_tokens_seen:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/accelerate/data_loader.py:452\u001B[0m, in \u001B[0;36mDataLoaderShard.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001B[39;00m\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 452\u001B[0m     current_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/transformers/trainer_utils.py:787\u001B[0m, in \u001B[0;36mRemoveColumnsCollator.__call__\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    785\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, features: List[\u001B[38;5;28mdict\u001B[39m]):\n\u001B[1;32m    786\u001B[0m     features \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remove_columns(feature) \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m features]\n\u001B[0;32m--> 787\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/transformers/data/data_collator.py:92\u001B[0m, in \u001B[0;36mdefault_data_collator\u001B[0;34m(features, return_tensors)\u001B[0m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m# In this function we'll make the assumption that all `features` in the batch\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;66;03m# have the same attributes.\u001B[39;00m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# So we will look at the first element as a proxy for what attributes exist\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# on the whole batch.\u001B[39;00m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m---> 92\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch_default_data_collator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m return_tensors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtf\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tf_default_data_collator(features)\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/transformers/data/data_collator.py:158\u001B[0m, in \u001B[0;36mtorch_default_data_collator\u001B[0;34m(features)\u001B[0m\n\u001B[1;32m    156\u001B[0m             batch[k] \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(np\u001B[38;5;241m.\u001B[39mstack([f[k] \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m features]))\n\u001B[1;32m    157\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m             batch[k] \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mf\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m batch\n",
      "\u001B[0;31mValueError\u001B[0m: expected sequence of length 28 at dim 1 (got 24)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = 'data/floorplan/floorplan_train.json'\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'room_type': 'master room',\n  'x': 102,\n  'y': 77,\n  'h': 59,\n  'w': 42,\n  'x_min': 73,\n  'y_min': 56,\n  'x_max': 131,\n  'y_max': 97,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'south west corner',\n  'size': '150',\n  'aspect ratio': '5 over 7',\n  'private': False},\n {'room_type': 'common room 1',\n  'x': 154,\n  'y': 96,\n  'h': 34,\n  'w': 47,\n  'x_min': 137,\n  'y_min': 73,\n  'x_max': 170,\n  'y_max': 119,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'north west corner',\n  'size': '100',\n  'aspect ratio': '11 over 8',\n  'private': False},\n {'room_type': 'balcony 1',\n  'x': 192,\n  'y': 139,\n  'h': 33,\n  'w': 12,\n  'x_min': 176,\n  'y_min': 133,\n  'x_max': 208,\n  'y_max': 144,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'north side',\n  'size': '25',\n  'aspect ratio': '4 over 11',\n  'private': True},\n {'room_type': 'bathroom',\n  'x': 154,\n  'y': 135,\n  'h': 34,\n  'w': 20,\n  'x_min': 137,\n  'y_min': 125,\n  'x_max': 170,\n  'y_max': 144,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'north side',\n  'size': '50',\n  'aspect ratio': '7 over 12',\n  'private': False},\n {'room_type': 'common room 2',\n  'x': 93,\n  'y': 124,\n  'h': 41,\n  'w': 42,\n  'x_min': 73,\n  'y_min': 103,\n  'x_max': 113,\n  'y_max': 144,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'south side',\n  'size': '100',\n  'aspect ratio': '1 over 1',\n  'private': False},\n {'room_type': 'kitchen',\n  'x': 192,\n  'y': 165,\n  'h': 33,\n  'w': 30,\n  'x_min': 176,\n  'y_min': 150,\n  'x_max': 208,\n  'y_max': 179,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'north side',\n  'size': '50',\n  'aspect ratio': '10 over 11',\n  'private': None},\n {'room_type': 'living room',\n  'x': 134,\n  'y': 152,\n  'h': 123,\n  'w': 98,\n  'x_min': 73,\n  'y_min': 103,\n  'x_max': 195,\n  'y_max': 200,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': None,\n  'size': '750',\n  'aspect ratio': '4 over 5',\n  'private': None},\n {'room_type': 'balcony 2',\n  'x': 58,\n  'y': 175,\n  'h': 20,\n  'w': 51,\n  'x_min': 48,\n  'y_min': 150,\n  'x_max': 67,\n  'y_max': 200,\n  'near_x_min': -1,\n  'near_y_min': -1,\n  'near_x_max': -1,\n  'near_y_max': -1,\n  'relation': [],\n  'location': 'south side',\n  'size': '50',\n  'aspect ratio': '5 over 2',\n  'private': False}]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['rooms']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'type'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m         string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroom\u001B[38;5;241m.\u001B[39mtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39mx_min)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39my_min)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39mx_max)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39my_max)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m string\n\u001B[0;32m---> 11\u001B[0m \u001B[43mformat_short_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[11], line 8\u001B[0m, in \u001B[0;36mformat_short_output\u001B[0;34m(example)\u001B[0m\n\u001B[1;32m      5\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m room \u001B[38;5;129;01min\u001B[39;00m example[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrooms\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;66;03m# string += f'{start_token} {room.type} {sep} x coordinate = {str(room.x)} {sep} y coordinate = {str(room.y)} {sep} height = {str(room.h)} {sep} width = {str(room.w)} {end_token} '\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m     string \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mroom\u001B[38;5;241m.\u001B[39mtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39mx_min)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39my_min)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39mx_max)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(room\u001B[38;5;241m.\u001B[39my_max)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m string\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'dict' object has no attribute 'type'"
     ]
    }
   ],
   "source": [
    "def format_short_output(example) -> str:\n",
    "    string = ''\n",
    "    start_token = '['\n",
    "    end_token = ']'\n",
    "    sep = '|'\n",
    "    for room in example['rooms']:\n",
    "        # string += f'{start_token} {room.type} {sep} x coordinate = {str(room.x)} {sep} y coordinate = {str(room.y)} {sep} height = {str(room.h)} {sep} width = {str(room.w)} {end_token} '\n",
    "        string += f'{room.type} {str(room.x_min)} {str(room.y_min)} {str(room.x_max)} {str(room.y_max)} '\n",
    "    return string\n",
    "\n",
    "format_short_output(data[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from datasets import FloorplanDataset\n",
    "\n",
    "floorplan_dataset = FloorplanDataset(tokenizer=tokenizer,max_input_length=512, max_output_length=512, data_args=data_args, seed=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "2246"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(floorplan_dataset.features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "datasets.FloorplanDataset"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(floorplan_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'short'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args.output_format_type"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "InputFeatures(input_ids=[4011, 1018, 63, 209, 19, 81, 505, 2418, 3, 4, 204, 2418, 3, 5, 100, 19, 1069, 269, 326, 13, 8, 1228, 3, 5, 4011, 1018, 63, 204, 19, 81, 335, 2418, 3, 4, 220, 2418, 3, 5, 100, 19, 5008, 3457, 13, 8, 629, 3, 5, 37, 2582, 19, 81, 505, 2418, 3, 4, 431, 2418, 3, 5, 94, 19, 1069, 344, 8, 840, 562, 11, 8, 1228, 3, 5, 7155, 562, 209, 19, 81, 335, 2418, 3, 4, 586, 2418, 3, 5, 37, 1017, 2801, 33, 1069, 26184, 45, 284, 119, 3, 5, 7155, 562, 204, 19, 81, 335, 2418, 3, 4, 335, 2418, 3, 5, 37, 1017, 2801, 33, 1069, 26184, 45, 284, 119, 3, 5, 37, 1228, 19, 3, 9, 335, 2418, 3, 4, 335, 2418, 562, 3, 5, 94, 1416, 114, 34, 19, 2946, 95, 12, 8, 840, 562, 3, 5, 37, 840, 562, 19, 1069, 30, 8, 5727, 596, 13, 8, 629, 3, 5, 94, 19, 3, 6489, 114, 3, 9, 332, 11, 34, 31, 7, 8, 2630, 562, 3, 5, 94, 19, 3241, 968, 1922, 3, 4, 3538, 1922, 3, 5, 1698, 562, 24, 25, 369, 91, 13, 25, 56, 2058, 8, 840, 562, 3, 5, 37, 2325, 19, 81, 335, 1922, 3, 4, 627, 1922, 3, 5, 94, 19, 1069, 623, 4653, 13, 8, 629, 3, 5, 94, 19, 3, 9, 26439, 2346, 3, 5, 1220, 8838, 11696, 204, 2368, 3, 23201, 3, 18, 3, 26937, 3, 19818, 204, 2606, 8003, 3, 18, 209, 3072, 3, 4440, 3, 19818, 9065, 3, 18, 209, 2518, 3, 20889, 3, 24622, 3, 3651, 3, 18, 3, 23757, 3, 4591, 3, 22823, 943, 3, 18, 6426, 3, 15660, 3, 16431, 943, 3, 18, 6426, 3, 23330, 3, 3436, 3, 25794, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], boundary_ids=None, boundary_mask=None, label_ids=[784, 1017, 562, 209, 1820, 3, 226, 11639, 3274, 3, 27308, 1820, 3, 63, 11639, 3274, 3, 4314, 1820, 3902, 3274, 6154, 1820, 9400, 3274, 10635, 3, 908, 784, 16940, 209, 1820, 3, 226, 11639, 3274, 3, 19978, 1820, 3, 63, 11639, 3274, 3, 24090, 1820, 3902, 3274, 5400, 1820, 9400, 3274, 586, 3, 908, 784, 16940, 204, 1820, 3, 226, 11639, 3274, 3, 3449, 1820, 3, 63, 11639, 3274, 209, 3072, 1820, 3902, 3274, 460, 1820, 9400, 3274, 11696, 3, 908, 784, 840, 562, 1820, 3, 226, 11639, 3274, 3, 23747, 1820, 3, 63, 11639, 3274, 3, 26320, 1820, 3902, 3274, 3, 14574, 1820, 9400, 3274, 3, 3916, 3, 908, 784, 1228, 1820, 3, 226, 11639, 3274, 3, 19978, 1820, 3, 63, 11639, 3274, 3, 22823, 1820, 3902, 3274, 5400, 1820, 9400, 3274, 604, 3, 908, 784, 1017, 562, 204, 1820, 3, 226, 11639, 3274, 3, 4271, 1820, 3, 63, 11639, 3274, 3, 22504, 1820, 3902, 3274, 8798, 1820, 9400, 3274, 6426, 3, 908, 784, 2325, 562, 1820, 3, 226, 11639, 3274, 3, 14388, 1820, 3, 63, 11639, 3274, 3, 4013, 1820, 3902, 3274, 3, 3390, 1820, 9400, 3274, 6426, 3, 908, 784, 2582, 1820, 3, 226, 11639, 3274, 3, 27308, 1820, 3, 63, 11639, 3274, 209, 2469, 1820, 3902, 3274, 6154, 1820, 9400, 3274, 460, 3, 908, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], num_rooms=8, regr_labels=[154, 96, 34, 47, 192, 139, 33, 12, 58, 175, 20, 51, 134, 152, 123, 98, 192, 165, 33, 30, 93, 124, 41, 42, 102, 77, 59, 42, 154, 135, 34, 20], decoder_attention_mask=None)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "floorplan_dataset.features[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        if feature is None:\n",
    "            return torch.zeros((1, )), torch.zeros((1, ))\n",
    "        return {\n",
    "            'input_ids': feature.input_ids,\n",
    "            'attention_mask': feature.attention_mask,\n",
    "            'boundary_ids': feature.boundary_ids,\n",
    "            'boundary_mask': feature.boundary_mask,\n",
    "            'num_rooms': feature.num_rooms,\n",
    "            'regr_labels': feature.regr_labels,\n",
    "            'decoder_attention_mask': feature.decoder_attention_mask,\n",
    "        }, feature.label_ids\n",
    "\n",
    "dataset = MyDataset(floorplan_dataset.features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:129\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:129\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:152\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    150\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[0;32m--> 152\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem_type))\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m DataLoader(dataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(batch)\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    217\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    141\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    141\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:132\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem}\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(elem, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_fields\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# namedtuple\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type(\u001B[38;5;241m*\u001B[39m(collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)))\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:132\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {key: \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem}\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(elem, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_fields\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# namedtuple\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type(\u001B[38;5;241m*\u001B[39m(collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)))\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:152\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m             \u001B[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001B[39;00m\n\u001B[1;32m    150\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[0;32m--> 152\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem_type))\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "for batch in dataloader:\n",
    "    print(batch)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:129\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:129\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:152\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    150\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[0;32m--> 152\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem_type))\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m2\u001B[39m):\n\u001B[0;32m----> 8\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[1;32m      9\u001B[0m         \u001B[38;5;66;03m# Unpack the batch\u001B[39;00m\n\u001B[1;32m     10\u001B[0m         inputs, targets \u001B[38;5;241m=\u001B[39m batch\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;66;03m# Move the inputs and targets to the same device as the model\u001B[39;00m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:277\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    217\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001B[39;00m\n\u001B[1;32m    219\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    141\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:144\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    141\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:132\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem}\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(elem, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_fields\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# namedtuple\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type(\u001B[38;5;241m*\u001B[39m(collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)))\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:132\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m elem_type({key: collate([d[key] \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m batch], collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem})\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    131\u001B[0m         \u001B[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001B[39;00m\n\u001B[0;32m--> 132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {key: \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43md\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m elem}\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(elem, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_fields\u001B[39m\u001B[38;5;124m'\u001B[39m):  \u001B[38;5;66;03m# namedtuple\u001B[39;00m\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m elem_type(\u001B[38;5;241m*\u001B[39m(collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch)))\n",
      "File \u001B[0;32m~/Developer/projects/t2f/venv/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:152\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    148\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    149\u001B[0m             \u001B[38;5;66;03m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001B[39;00m\n\u001B[1;32m    150\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]\n\u001B[0;32m--> 152\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(default_collate_err_msg_format\u001B[38;5;241m.\u001B[39mformat(elem_type))\n",
      "\u001B[0;31mTypeError\u001B[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(2):\n",
    "    for batch in dataloader:\n",
    "        # Unpack the batch\n",
    "        inputs, targets = batch\n",
    "\n",
    "        # Move the inputs and targets to the same device as the model\n",
    "        inputs = {name: tensor.to(model.device) for name, tensor in inputs.items()}\n",
    "        targets = targets.to(model.device)\n",
    "\n",
    "        # Forward pass: feed the inputs to the model and get the outputs\n",
    "        outputs = model(**inputs, labels=targets)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass: compute the gradients of the loss w.r.t. the model's parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model's parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
